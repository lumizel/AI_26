{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lumizel/AI_26/blob/main/05_03_%ED%8A%B8%EB%A6%AC%EC%9D%98%EC%95%99%EC%83%81%EB%B8%94.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:28.805440Z",
          "start_time": "2026-02-27T06:28:28.774343800Z"
        },
        "id": "initial_id"
      },
      "source": [
        "# 지금까지 k-최근접이웃알고리즘, 선형회귀, 릿지, 라쏘, 다항회귀, 로지스틱회귀\n",
        "# 등을 배웠고 확률적경사하강법을 이용한 분류과 결정트리 모델까지 학습을 함\n",
        "\n",
        "# 테스트 세트말고 검증세트를 사용하는 cv(교차검증), 하이퍼파라미터튜닝등을 사용\n",
        "\n",
        "# 코렙에는 왠만한 AI용 라이브러리가 설치 되어 있는데 안되어 있는 것은 수동 설치!!!\n",
        "# !pip install xgboost\n",
        "# !pip install pycaret\n",
        "# 이미 설치완료"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:28.869956300Z",
          "start_time": "2026-02-27T06:28:28.824753900Z"
        },
        "id": "f23545a765e971e9"
      },
      "cell_type": "code",
      "source": [
        "# 앙상블 : 단어 그대로 여러 단순한 모델을 결합하여 정확한 모델을 만드는 방법\n",
        "# 정형데이터 : 지금까지 학습한 수치자료가 있는 값\n",
        "# 비정형데이터 : 데이터베이스나 엑셀로 표현하기 어려운 데이터\n",
        "#       (텍스트데이터, 디카사진, mp3 등.) -> 신경망 알고리즘\n",
        "\n",
        "# 랜덤 포레스트 : 결정 트리를 랜덤하게 만들어 결정트리(나무)숲 을 만듬\n",
        "#       -> 최종 예측\n",
        "\n",
        "# 1000개의 샘플이 들어 있는 가방에서 100개을 샘플을 뽑을때 1개를 뽑고\n",
        "# 뽑앗던 1개를 다시 가방에 넣음\n",
        "# 중복된 샘플을 뽑을 수 있음 -> 부트스트랩 샘플이라고 함\n",
        "# 부트스트랩 : 데이터 세트에서 중복을 허용하여 데이터를 샘플링"
      ],
      "id": "f23545a765e971e9",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "481dac10b676f5df"
      },
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:c197d5f7-b7fb-41e2-8c49-d9ecc5a427df.png)"
      ],
      "id": "481dac10b676f5df"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:28.935794700Z",
          "start_time": "2026-02-27T06:28:28.887957Z"
        },
        "id": "235c44f07e94252d"
      },
      "cell_type": "code",
      "source": [
        "# 분류 모델인 : RandomForestClassifier는\n",
        "#   기본적으로 전체 특성 개수의 제곱근만큼 특성을 선택한다.\n",
        "# 즉 4개의 특성이 있다면 노드마다 2개를 랜덤하게 선택하여 사용\n",
        "# 다만 회귀 모델인 RandomForestRegressor는 전체 특성을 사용\n",
        "# 사이킷 런의 랜덤 포레스트는 기본적으로 100개의 결정 트리를 이런 방식으로 훈련한다.\n",
        "\n",
        "# 그 다음 분류일 때는 각 트리의 클래스별 확률을 평균하여\n",
        "# 가장 높은 확율을 가진 클래스를 예측으로 삼는다.\n",
        "# 회귀일 때는 단순히 각 트리의 예측을 평균함.\n",
        "\n",
        "# 분류 : 샘플을 몇개의 클래스 중 하나로 분류하는 문제\n",
        "# 회귀 : 임의의 어떤 숫자를 예측하는 문제"
      ],
      "id": "235c44f07e94252d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "85a4ce172b8bfeab"
      },
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:b16d3e15-cec2-41de-9afc-de8cd1770fce.png)"
      ],
      "id": "85a4ce172b8bfeab"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:29.268254200Z",
          "start_time": "2026-02-27T06:28:28.939791300Z"
        },
        "id": "b5040258f7cc0a49",
        "outputId": "c0695c26-22fc-4e34-ab1c-955e1f60fbcc"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import io\n",
        "import urllib3\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. \"보안 검증 안 해도 되니까 경고 띄우지 마!\" 설정\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "# 2. requests로 데이터를 강제로 가져오기 (verify=False가 핵심)\n",
        "url = 'https://bit.ly/wine_csv_data'\n",
        "response = requests.get(url, verify=False)\n",
        "\n",
        "# 3. 판다스에게 주소 대신 '이미 가져온 데이터'를 읽으라고 시키기\n",
        "# pd.read_csv('https://...') 대신 아래 방식을 써야 에러가 안 납니다!\n",
        "wine = pd.read_csv(io.StringIO(response.text))\n",
        "\n",
        "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
        "target = wine['class'].to_numpy()\n",
        "data # print 생략 가능"
      ],
      "id": "b5040258f7cc0a49",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 9.4 ,  1.9 ,  3.51],\n",
              "       [ 9.8 ,  2.6 ,  3.2 ],\n",
              "       [ 9.8 ,  2.3 ,  3.26],\n",
              "       ...,\n",
              "       [ 9.4 ,  1.2 ,  2.99],\n",
              "       [12.8 ,  1.1 ,  3.34],\n",
              "       [11.8 ,  0.8 ,  3.26]])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:29.284138700Z",
          "start_time": "2026-02-27T06:28:29.269254400Z"
        },
        "id": "85712cb69cb8e8e4",
        "outputId": "7eb3dd5f-a247-4b41-a26b-0a5a30f5528e"
      },
      "cell_type": "code",
      "source": [
        "target # print 생략 가능"
      ],
      "id": "85712cb69cb8e8e4",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 1., 1.])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:29.337643400Z",
          "start_time": "2026-02-27T06:28:29.304642900Z"
        },
        "id": "de8f3e77aed66c7",
        "outputId": "9f97425f-2928-4081-d2b9-d99255662c1f"
      },
      "cell_type": "code",
      "source": [
        "# 훈련세트 80% 와 테스트세트 20% 로 나눔\n",
        "train_input, test_input, train_target, test_target = train_test_split(\n",
        "    data, target, test_size=0.2, random_state=42)\n",
        "print(train_input.shape, test_input.shape )\n",
        "# 여기서 만든 테스트 20%는 검증이 끝난 마지막 단계에서 평가용으로 사용"
      ],
      "id": "de8f3e77aed66c7",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5197, 3) (1300, 3)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:29.886552900Z",
          "start_time": "2026-02-27T06:28:29.338643600Z"
        },
        "id": "67a0297d5f786643",
        "outputId": "d26957c7-9451-40fe-f90c-cdd5e4499f2d"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate # 크로즈 검증용\n",
        "from sklearn.ensemble import RandomForestClassifier # 100개의 결정트리 사용\n",
        "\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42) # n_jobs=-1 모든 cpu 사용\n",
        "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "# return_train_score=True 검증 점수와 훈련 세트에 대한 점수도 리턴\n",
        "\n",
        "print(np.mean(scores['train_score']))\n",
        "print(np.mean(scores['test_score']))\n",
        "# train_score 과대 적합 0.9973541965122431"
      ],
      "id": "67a0297d5f786643",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9973541965122431\n",
            "0.8905151032797809\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:30.143793Z",
          "start_time": "2026-02-27T06:28:29.887554500Z"
        },
        "id": "bf5ad85cb6bff082",
        "outputId": "af6e1b60-be60-47a4-9ea0-ba2db7862f51"
      },
      "cell_type": "code",
      "source": [
        "# 랜덤 포레스트는 결정트리의 앙상블이기 때문에 결정트리가 제공하는 중요한 매개변수를 모두 제공\n",
        "# 결정 트리의 큰 장점 중 하나인 특성 중요를 계산\n",
        "# 랜덤 포레스트의 특성 중요도는 각 결정 트리의 특성 중요도를 취한 것\n",
        "# 훈련 후 에 중요도를 출력\n",
        "rf.fit(train_input, train_target) # 훈련 후 특성 중요도 출력\n",
        "print(rf.feature_importances_)"
      ],
      "id": "bf5ad85cb6bff082",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.23167441 0.50039841 0.26792718]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:30.156301100Z",
          "start_time": "2026-02-27T06:28:30.148792900Z"
        },
        "id": "7814060dcb81e4f2"
      },
      "cell_type": "code",
      "source": [
        "# [0.23167441 0.50039841 0.26792718] 랜덤포레스트 현재 결과\n",
        "# [0.12345626 0.86862934 0.0079144 ] LogisticRegression 이전 결과\n",
        "\n",
        "# 알콜도수   , 당도      , pH 비교 해보자.\n",
        "# 당도의 중요도가 감소하고, 알콜 도수와 pH 중요도가 상승함\n",
        "# 이유는 랜덤포레스트가 특성 일부를 랜덤하게 선택하여 결정 트리를 훈련함(중복허용)\n",
        "# 하나의 특성에 과도하게 집중하지 않고 좀 더 많은 특성이 훈련에 기여할 기회가 됨(과대적합을 줄임)"
      ],
      "id": "7814060dcb81e4f2",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:30.465806500Z",
          "start_time": "2026-02-27T06:28:30.157538600Z"
        },
        "id": "b3ac5dbc58387767",
        "outputId": "c2502b57-f179-4509-8ee5-d0c2d51248d8"
      },
      "cell_type": "code",
      "source": [
        "# RandomForestClassifier기능중에 자체적으로 모델을 평가하는 점수를 얻을 수 있다.\n",
        "# OOB(Out Of Bag)부트스트랩에 포함되지 않고 남은 샘플 -> 결정 트리 평가용(검증 세트로 활용)\n",
        "# oob_score=True -> 랜덤 포레스트는 각 결정 트리의 OOB 점수를 평균하여 출력(oob_score_)\n",
        "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
        "\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.oob_score_) # 교차 검증 점수와 비슷한 결과를 얻음\n",
        "# OOB 점수를 사용하면 교차 검증을 대신할 수 있어 결과적으로 훈련 세트에 더 많은 샘플을 사용할수 있음\n",
        "################### RandomForestClassifier 끝 ###########################"
      ],
      "id": "b3ac5dbc58387767",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8934000384837406\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:30.957372400Z",
          "start_time": "2026-02-27T06:28:30.466807200Z"
        },
        "id": "974bd40b07f7a77a",
        "outputId": "188c710d-f021-4211-8fde-a1be061887b8"
      },
      "cell_type": "code",
      "source": [
        "# 엑스트라 트리 : 100개의 결정 트리 훈련 -> 부트스트랩 샘플을 사용하지 않음(전체 훈련세트 사용)\n",
        "# 대신 노드를 분할할 때 가장 좋은 분할을 찾는 것이 아니라 무작위로 분할함!\n",
        "# 엑스트라 트리의 결정 트리 splitter='random'\n",
        "# 하나의 결정 트리에서 특성을 무작위로 분할한다면 성능이 낮아지겠지만\n",
        "# 많은 트리를 앙상블 하기 때문에 과대 적합을 막고 검증세트의 점수를 높이는 효과가 있다.\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier # ExtraTreesClassifier 엑스트라 트리\n",
        "\n",
        "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(et, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']))\n",
        "print(np.mean(scores['test_score']))\n",
        "\n",
        "# RandomForestClassifier와 결과가 비슷함. 대신 속도가 빠름"
      ],
      "id": "974bd40b07f7a77a",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9974503966084433\n",
            "0.8887848893166506\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:31.168829Z",
          "start_time": "2026-02-27T06:28:30.958697600Z"
        },
        "id": "4444a7d9d260f436",
        "outputId": "718774c2-7524-407f-ea59-74354b4a945e"
      },
      "cell_type": "code",
      "source": [
        "et.fit(train_input, train_target)\n",
        "print(et.feature_importances_)\n",
        "# [0.20183568 0.52242907 0.27573525] 엑스트라 트리 현재 결과\n",
        "# [0.23167441 0.50039841 0.26792718] 랜덤포레스트 이전 결과\n",
        "# [0.12345626 0.86862934 0.0079144 ] LogisticRegression 이전 결과\n",
        "# 특성 중요도를 보면 결정 트리보다 당도에 대한 의존성이 작다.\n",
        "##################### 엑스트라 트리 끝 ###########################"
      ],
      "id": "4444a7d9d260f436",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.20183568 0.52242907 0.27573525]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "8c6580696d8e0f9f"
      },
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:e552002a-6ceb-4b3b-a4f5-dc9bb40d5faf.png)"
      ],
      "id": "8c6580696d8e0f9f"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:31.657820300Z",
          "start_time": "2026-02-27T06:28:31.169830400Z"
        },
        "id": "c71a7263730567aa",
        "outputId": "94df2b1e-37b4-4643-a0b3-55b76b1f5f24"
      },
      "cell_type": "code",
      "source": [
        "# 그레이디언트 부스팅 Gradient Boosting(기울기)\n",
        "# 깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식으로 앙상블\n",
        "# 사이킷 런의 GradientBoostingClassifier는 기본적으로 깊이가 3인 결정 트리를 100개 사용\n",
        "# 때문에 과대적합에 강하고 일반적인 높은 일반화 성능을 기대함\n",
        "\n",
        "# Gradient는 경사 하강법을 사용하여 트리를 앙상블에 추가함.\n",
        "# 분류 : 로지스틱 손실 함수, 회귀에서는 평균 제급 오차 함수를 사용\n",
        "# 경사 하강법 손실 함수를 산으로 정의하고 가장 낮은 곳으로 찾아 내려오는 과정\n",
        "\n",
        "# 가장 낮은 곳으로 내려오는 방법은 모델의 가중치와 절편을 조금씩 바꾸는 것\n",
        "# 결정 트리를 계속 추가하면서 가장 낮은 곳을 찾아 이동, 손실함수의 낮은 곳으로 천천히 이동\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "#                            GradientBoostingClassifier 그레디언트 부스팅\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']))\n",
        "print(np.mean(scores['test_score']))\n",
        "# 과대 적합 해결 0.8881086892152563 0.8720430147331015"
      ],
      "id": "c71a7263730567aa",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8881086892152563\n",
            "0.8720430147331015\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "2f4ebc1bc38242b9"
      },
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:ea464e06-1fab-4ef4-a25b-e75a64420957.png)"
      ],
      "id": "2f4ebc1bc38242b9"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:33.583429200Z",
          "start_time": "2026-02-27T06:28:31.659825600Z"
        },
        "id": "f6c77647cc3e8969",
        "outputId": "39c1251f-9282-4a59-8dbc-b21a48f90cbe"
      },
      "cell_type": "code",
      "source": [
        "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
        "# n_estimators=500 결정트리개수를 500개로 늘림 기본값 100\n",
        "# learning_rate=0.2 학습률 기본값 0.1\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score'])) # 교차 검증 점수 확인\n",
        "# 94.64% 87.80% 훈련과, 검증 점수차이가 10%이상 나지 않으면 괜찮음(과대적합 아님)"
      ],
      "id": "f6c77647cc3e8969",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9464595437171814 0.8780082549788999\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:35.027313800Z",
          "start_time": "2026-02-27T06:28:33.584431300Z"
        },
        "id": "a64452ad63cb1453",
        "outputId": "8d1f1d85-35e9-4103-a773-a09f25fe31e0"
      },
      "cell_type": "code",
      "source": [
        "gb.fit(train_input, train_target) # 훈련시작\n",
        "print(gb.feature_importances_) # 당도에 의존도가 낮음\n",
        "# 그레이디언트 부스팅이 랜덤포레스트보다 조금 더 높은 성능이 있다.\n",
        "# 하지만 순서대로 트리를 추가하기 때문에 훈련속도가 좀 느리다.\n",
        "# GradientBoostingClassifier에는 n_jobs=-1 매개값이 없다.(구형모델이라)"
      ],
      "id": "a64452ad63cb1453",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.15882696 0.6799705  0.16120254]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:35.060777600Z",
          "start_time": "2026-02-27T06:28:35.037374Z"
        },
        "id": "ddd302d7697052cd"
      },
      "cell_type": "code",
      "source": [
        "# [0.15887763 0.6799705  0.16115187] 그레이디언트 부스팅 현재 결과\n",
        "# [0.20183568 0.52242907 0.27573525] 엑스트라 트리 이전 결과\n",
        "# [0.23167441 0.50039841 0.26792718] 랜덤포레스트 이전 결과\n",
        "# [0.12345626 0.86862934 0.0079144 ] LogisticRegression 이전 결과\n",
        "#################### 그레이디언트 부스팅 끝 ##########################"
      ],
      "id": "ddd302d7697052cd",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:35.418349600Z",
          "start_time": "2026-02-27T06:28:35.065777300Z"
        },
        "id": "63df9522141233b3",
        "outputId": "ae3aeecf-a9d0-4d67-d88d-1e2025a9b07c"
      },
      "cell_type": "code",
      "source": [
        "# 히스토그램 기반 그레이언트 부스팅 Histogram Gradient : 그레이디언트 부스팅의 개선버전\n",
        "# 입력 특성을 256 구간으로 나눔 -> 노드를 분할할 때 최적의 분할을 매우 빠르게 찾을 수 있다.\n",
        "# 특히 256구간 중에서 하나를 떼어 놓고 누락된 값을 위해서 사용함\n",
        "# HistGradientBoostingClassifier는 기본 매개변수에서 안정적인 성능을 얻을 수있다.\n",
        "# HistGradientBoostingClassifier에는 트리의 개수를 지정하는데\n",
        "# n_estimators 대신 max_iter를 사용함(성능 향상용)\n",
        "\n",
        "# from sklearn.experimental import enable_hist_gradient_boosting 아직 개발중\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier # 분류용\n",
        "\n",
        "hgb = HistGradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(hgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score'])) # 과대 적합 억제 성공!\n"
      ],
      "id": "63df9522141233b3",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9321723946453317 0.8801241948619236\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:36.390990800Z",
          "start_time": "2026-02-27T06:28:35.420342500Z"
        },
        "id": "90a1decff000cccc",
        "outputId": "11f31aef-aa10-46f4-d25a-22ce5d0c432d"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "# permutation_importance 특성 중요도 확인\n",
        "# : 특성을 하나씩 랜덤하게 섞어서 모델의 성능이 변화되는지 관찰\n",
        "\n",
        "# 히스토그램 기반의 훈련을 진행 -> 훈련세트에서 특성 중요도를 계산\n",
        "hgb.fit(train_input, train_target)\n",
        "\n",
        "#n_repeats=10 랜덤하게 섞을 횟수 (기본 5)\n",
        "result = permutation_importance(hgb, train_input, train_target, n_repeats=10,random_state=42, n_jobs=-1)\n",
        "\n",
        "print(result.importances_mean)\n",
        "# 알콜도수   , 당도    , pH          비교 해보자.\n",
        "# [0.08876275 0.23438522 0.08027708] 히스토그램 현재결과\n",
        "# [0.15887763 0.6799705  0.16115187] 그레이디언트 부스팅 이전 결과\n",
        "# [0.20183568 0.52242907 0.27573525] 엑스트라 트리 이전 결과\n",
        "# [0.23167441 0.50039841 0.26792718] 랜덤포레스트 이전 결과\n",
        "# [0.12345626 0.86862934 0.0079144 ] LogisticRegression 이전 결과"
      ],
      "id": "90a1decff000cccc",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.08876275 0.23438522 0.08027708]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:36.652194100Z",
          "start_time": "2026-02-27T06:28:36.391992200Z"
        },
        "id": "eec3f1de9bb1b632",
        "outputId": "9d9650db-b6a3-4f6b-9970-ea7aec219ec1"
      },
      "cell_type": "code",
      "source": [
        "# 테스트 결과 확인\n",
        "result = permutation_importance(hgb, test_input, test_target, n_repeats=10, random_state=42, n_jobs=-1)\n",
        "\n",
        "print(result.importances_mean)\n",
        "# 알콜도수   , 당도    , pH          비교 해보자.\n",
        "# [0.05969231 0.20238462 0.049     ] 히스토그램 테스트 세트에서 현재 결과\n",
        "# [0.08876275 0.23438522 0.08027708] 히스토그램 훈련 세트 이전결과\n",
        "# [0.15887763 0.6799705  0.16115187] 그레이디언트 부스팅 이전 결과\n",
        "# [0.20183568 0.52242907 0.27573525] 엑스트라 트리 이전 결과\n",
        "# [0.23167441 0.50039841 0.26792718] 랜덤포레스트 이전 결과\n",
        "# [0.12345626 0.86862934 0.0079144 ] LogisticRegression 이전 결과\n",
        "\n",
        "# HistGradientBoostingRegressor 히스토그램 기반 그레이디언트 부스팅의 회귀 버전\n",
        "###################### 히스토그램 기반 그레이디언트 끝 ########################"
      ],
      "id": "eec3f1de9bb1b632",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.05969231 0.20238462 0.049     ]\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:36.765790100Z",
          "start_time": "2026-02-27T06:28:36.653194600Z"
        },
        "id": "eec18f4ebeacd449",
        "outputId": "79acfd63-148f-4214-a784-64ba497d857c"
      },
      "cell_type": "code",
      "source": [
        "# 사이킷런 말고도 그레이디언트 부스팅 알고리즘을 구현한 라이브러리가 다수 존재\n",
        "# XGBoost 대표적임 -> 크로스검증이 가능(cross_validate())\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# tree_method='hist' 히스토그램 기반 그레이디언트 부스팅용\n",
        "# 만약 안되면 파이썬에 설치가 안된것임\n",
        "# !pip install xgboost\n",
        "# !pip install pycaret -> 세션 다시 시작하고 위에서부터 다시 객체 생성함\n",
        "\n",
        "xgb = XGBClassifier(tree_method='hist', random_state=42)\n",
        "scores = cross_validate(xgb, train_input, train_target,return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']))\n",
        "print(np.mean(scores['test_score']))\n",
        "# 95.58% , 87.82% 와인 교차 검증 점수"
      ],
      "id": "eec18f4ebeacd449",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9567059184812372\n",
            "0.8783915747390243\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "2bbbc348eecd657b"
      },
      "cell_type": "markdown",
      "source": [
        "![image.png](attachment:b62760ba-3a0e-42d7-98dd-8100d3eaa88f.png)"
      ],
      "id": "2bbbc348eecd657b"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2026-02-27T06:28:37.267169400Z",
          "start_time": "2026-02-27T06:28:36.777788500Z"
        },
        "id": "c418d83728b1c61d",
        "outputId": "f78ebf97-5276-43ed-d32c-a60535e66a4b"
      },
      "cell_type": "code",
      "source": [
        "# LGBMClassifier ms에서 만든 LightGBM^2\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgb = LGBMClassifier(random_state=42)\n",
        "scores = cross_validate(lgb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score']))\n",
        "# 93.58% , 88.01%"
      ],
      "id": "c418d83728b1c61d",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.935828414851749 0.8801251203079884\n"
          ]
        }
      ],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}